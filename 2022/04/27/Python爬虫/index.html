<!DOCTYPE html><html class="dark" lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="theme-color" content="#0078E7"><meta name="author" content="Scary Pig"><meta name="copyright" content="Scary Pig"><meta name="generator" content="Hexo 6.3.0"><meta name="theme" content="hexo-theme-yun"><title>Python爬虫 | 咕噜咕噜~~</title><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/star-markdown-css@0.4.1/dist/yun/yun-markdown.min.css"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/prism-theme-vars/base.css"><script src="https://fastly.jsdelivr.net/npm/scrollreveal/dist/scrollreveal.min.js" defer></script><script>function initScrollReveal() {
  [".post-card",".markdown-body img"].forEach((target)=> {
    ScrollReveal().reveal(target);
  })
}
document.addEventListener("DOMContentLoaded", initScrollReveal);
document.addEventListener("pjax:success", initScrollReveal);
</script><link rel="icon" type="image/svg+xml" href="/myblog/yun.svg"><link rel="mask-icon" href="/myblog/yun.svg" color="#0078E7"><link rel="preload" href="/myblog/css/hexo-theme-yun.css" as="style"><link rel="prefetch" href="/myblog/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><link rel="preconnect" href="https://fastly.jsdelivr.net/npm/" crossorigin><script id="yun-config">
    window.Yun = {}
    window.CONFIG = {"hostname":"scarypig.github.io","root":"/myblog/","title":"春风十里不如你","version":"1.10.9","mode":"dark","copycode":true,"page":{"isPost":true},"i18n":{"placeholder":"搜索...","empty":"找不到您查询的内容: ${query}","hits":"找到 ${hits} 条结果","hits_time":"找到 ${hits} 条结果（用时 ${time} 毫秒）"},"anonymous_image":"https://cdn.yunyoujun.cn/img/avatar/none.jpg","say":{"api":"https://el-bot-api.vercel.app/api/words/young"},"vendors":{"host":"https://fastly.jsdelivr.net/npm/","darken":"https://fastly.jsdelivr.net/npm/darken@1.5.0"}};
  </script><link rel="stylesheet" href="/myblog/css/hexo-theme-yun.css"><script src="/myblog/js/hexo-theme-yun.js" type="module"></script><meta name="description" content="Robots协议User-agent: * Disallow: &#x2F; 对于所有用户，不允许爬取任何数据 查看方式123https:&#x2F;&#x2F;www.bilibili.com👇👇👇👇👇👇👇👇👇👇👇👇👇👇https:&#x2F;&#x2F;www.bilibili.com&#x2F;robots.txt  requests先来一个例子看一下使用过程1234567&gt;&gt;&gt; import">
<meta property="og:type" content="article">
<meta property="og:title" content="Python爬虫">
<meta property="og:url" content="https://scarypig.github.io/myblog/2022/04/27/Python%E7%88%AC%E8%99%AB/index.html">
<meta property="og:site_name" content="咕噜咕噜~~">
<meta property="og:description" content="Robots协议User-agent: * Disallow: &#x2F; 对于所有用户，不允许爬取任何数据 查看方式123https:&#x2F;&#x2F;www.bilibili.com👇👇👇👇👇👇👇👇👇👇👇👇👇👇https:&#x2F;&#x2F;www.bilibili.com&#x2F;robots.txt  requests先来一个例子看一下使用过程1234567&gt;&gt;&gt; import">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2022-04-27T07:09:32.311Z">
<meta property="article:modified_time" content="2023-05-08T09:29:42.915Z">
<meta property="article:author" content="Scary Pig">
<meta property="article:tag" content="python">
<meta name="twitter:card" content="summary"><script>(function() {
  if (CONFIG.mode !== 'auto') return
  const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches
  const setting = localStorage.getItem('darken-mode') || 'auto'
  if (setting === 'dark' || (prefersDark && setting !== 'light'))
    document.documentElement.classList.toggle('dark', true)
})()</script></head><body><script src="https://code.iconify.design/2/2.1.1/iconify.min.js"></script><script>// Define global variable
IconifyProviders = {
  // Empty prefix: overwrite default API provider configuration
  '': {
    // Use custom API first, use Iconify public API as backup
    resources: [
        'https://api.iconify.design',
    ],
    // Wait for 1 second before switching API hosts
    rotate: 1000,
  },
};</script><div class="container"><a class="sidebar-toggle hty-icon-button" id="menu-btn"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><div class="sidebar-toggle sidebar-overlay"></div><aside class="sidebar"><script src="/myblog/js/sidebar.js" type="module"></script><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc hty-icon-button sidebar-nav-active" data-target="post-toc-wrap" title="文章目录"><span class="icon iconify" data-icon="ri:list-ordered"></span></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="站点概览"><span class="icon iconify" data-icon="ri:passport-line"></span></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/myblog/about/" title="Scary Pig"><img width="96" loading="lazy" src="/myblog/yun.png" alt="Scary Pig"></a><div class="site-author-name"><a href="/myblog/about/">Scary Pig</a></div><span class="site-name">咕噜咕噜~~</span><sub class="site-subtitle"></sub><div class="site-description"></div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/myblog/" title="首页"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:home-4-line"></span></span></a><div class="site-state-item"><a href="/myblog/archives/" title="归档"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:archive-line"></span></span><span class="site-state-item-count">53</span></a></div><div class="site-state-item"><a href="/myblog/categories/" title="分类"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:folder-2-line"></span></span><span class="site-state-item-count">1</span></a></div><div class="site-state-item"><a href="/myblog/tags/" title="标签"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:price-tag-3-line"></span></span><span class="site-state-item-count">24</span></a></div><a class="site-state-item hty-icon-button" target="_blank" rel="noopener" href="https://yun.yunyoujun.cn" title="文档"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:settings-line"></span></span></a></nav><hr style="margin-bottom:0.5rem"><div class="links-of-author"><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://github.com/ScaryPig" title="GitHub" target="_blank" style="color:#6e5494"><span class="icon iconify" data-icon="ri:github-line"></span></a></div><hr style="margin:0.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="/myblog/links/" title="我的小伙伴们" style="color:dodgerblue"><span class="icon iconify" data-icon="ri:genderless-line"></span></a></div></div><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Robots%E5%8D%8F%E8%AE%AE"><span class="toc-number">1.</span> <span class="toc-text">Robots协议</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8B%E6%96%B9%E5%BC%8F"><span class="toc-number">1.1.</span> <span class="toc-text">查看方式</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#requests"><span class="toc-number">2.</span> <span class="toc-text">requests</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%88%E6%9D%A5%E4%B8%80%E4%B8%AA%E4%BE%8B%E5%AD%90%E7%9C%8B%E4%B8%80%E4%B8%8B%E4%BD%BF%E7%94%A8%E8%BF%87%E7%A8%8B"><span class="toc-number">2.1.</span> <span class="toc-text">先来一个例子看一下使用过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E6%B3%95"><span class="toc-number">2.2.</span> <span class="toc-text">方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%82%E5%B8%B8"><span class="toc-number">2.3.</span> <span class="toc-text">异常</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%A0%E5%8F%82"><span class="toc-number">2.4.</span> <span class="toc-text">传参</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E6%A1%86%E6%9E%B6"><span class="toc-number">2.5.</span> <span class="toc-text">代码框架</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90"><span class="toc-number">3.</span> <span class="toc-text">数据分析</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#re"><span class="toc-number">3.1.</span> <span class="toc-text">re</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#bs4"><span class="toc-number">3.2.</span> <span class="toc-text">bs4</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#xpath"><span class="toc-number">3.3.</span> <span class="toc-text">xpath</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#UA%E4%BC%AA%E8%A3%85"><span class="toc-number">4.</span> <span class="toc-text">UA伪装</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#cookie"><span class="toc-number">5.</span> <span class="toc-text">cookie</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%A3%E7%90%86"><span class="toc-number">6.</span> <span class="toc-text">代理</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8D%8F%E7%A8%8B"><span class="toc-number">7.</span> <span class="toc-text">协程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#greenlet%E6%A8%A1%E5%9D%97"><span class="toc-number">7.1.</span> <span class="toc-text">greenlet模块</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#yield%E5%85%B3%E9%94%AE%E5%AD%97"><span class="toc-number">7.2.</span> <span class="toc-text">yield关键字</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#asyncio%E8%A3%85%E9%A5%B0%E5%99%A8-3-4"><span class="toc-number">7.3.</span> <span class="toc-text">asyncio装饰器(3.4)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#asyn%E3%80%81await%E5%85%B3%E9%94%AE%E5%AD%97-3-5"><span class="toc-number">7.4.</span> <span class="toc-text">asyn、await关键字(3.5)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Task%E5%AF%B9%E8%B1%A1"><span class="toc-number">7.5.</span> <span class="toc-text">Task对象</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BC%82%E6%AD%A5%E7%88%AC%E8%99%AB"><span class="toc-number">8.</span> <span class="toc-text">异步爬虫</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#aiohttp"><span class="toc-number">9.</span> <span class="toc-text">aiohttp</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#selenium"><span class="toc-number">10.</span> <span class="toc-text">selenium</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#scrapy%E6%A1%86%E6%9E%B6"><span class="toc-number">11.</span> <span class="toc-text">scrapy框架</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%88%AC%E8%99%AB%E7%BC%96%E5%86%99"><span class="toc-number">11.1.</span> <span class="toc-text">爬虫编写</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8"><span class="toc-number">11.2.</span> <span class="toc-text">持久化存储</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%87%E5%AD%97%E5%AD%98%E5%82%A8"><span class="toc-number">11.3.</span> <span class="toc-text">文字存储</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E9%A1%B5%E7%88%AC%E5%8F%96"><span class="toc-number">11.4.</span> <span class="toc-text">分页爬取</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E7%88%AC%E5%8F%96"><span class="toc-number">11.5.</span> <span class="toc-text">深度爬取</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE%E7%89%87%E5%AD%98%E5%82%A8"><span class="toc-number">11.6.</span> <span class="toc-text">图片存储</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CrawlSpider"><span class="toc-number">11.7.</span> <span class="toc-text">CrawlSpider</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BC%AA%E9%93%BE%E6%8E%A5%E3%80%81%E4%BC%AA%E5%B1%9E%E6%80%A7"><span class="toc-number">12.</span> <span class="toc-text">伪链接、伪属性</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E7%88%AC%E8%99%AB"><span class="toc-number">13.</span> <span class="toc-text">分布式爬虫</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%88%AC%E5%8F%96%E6%90%9C%E7%B4%A2%E7%BB%93%E6%9E%9C"><span class="toc-number">14.</span> <span class="toc-text">爬取搜索结果</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%BE%E7%89%87%E7%88%AC%E5%8F%96"><span class="toc-number">15.</span> <span class="toc-text">图片爬取</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BE%8B-%E6%B7%98%E5%AE%9D%E7%88%AC%E5%8F%96"><span class="toc-number">16.</span> <span class="toc-text">例 淘宝爬取</span></a></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="hty-card post-block" itemscope itemtype="https://schema.org/Article" style="--smc-primary:#0078E7;"><link itemprop="mainEntityOfPage" href="https://scarypig.github.io/myblog/myblog/2022/04/27/Python%E7%88%AC%E8%99%AB/"><span hidden itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="name" content="Scary Pig"><meta itemprop="description"></span><span hidden itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><meta itemprop="name" content="咕噜咕噜~~"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">Python爬虫</h1><div class="post-meta"><div class="post-time"><span class="post-meta-item-icon"><span class="icon iconify" data-icon="ri:calendar-line"></span></span> <time title="创建时间：2022-04-27 15:09:32" itemprop="dateCreated datePublished" datetime="2022-04-27T15:09:32+08:00">2022-04-27</time><span class="post-meta-divider">-</span><span class="post-meta-item-icon"><span class="icon iconify" data-icon="ri:calendar-2-line"></span></span> <time title="修改时间：2023-05-08 17:29:42" itemprop="dateModified" datetime="2023-05-08T17:29:42+08:00">2023-05-08</time></div><div class="post-classify"><span class="post-category"> <span class="post-meta-item-icon" style="margin-right:3px;"><span class="icon iconify" data-icon="ri:folder-line"></span></span><span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category-item" href="/myblog/categories/%E5%AD%A6%E4%B9%A0/" style="--text-color:var(--hty-text-color)" itemprop="url" rel="index"><span itemprop="text">学习</span></a></span></span><span class="post-tag"><span class="post-meta-divider">-</span><a class="tag-item" href="/myblog/tags/python/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><span class="icon iconify" data-icon="ri:price-tag-3-line"></span></span><span class="tag-name">python</span></a></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content markdown-body"><h1 id="Robots协议"><a href="#Robots协议" class="headerlink" title="Robots协议"></a>Robots协议</h1><p>User-agent: *</p>
<p>Disallow: &#x2F;</p>
<p>对于所有用户，不允许爬取任何数据</p>
<h2 id="查看方式"><a href="#查看方式" class="headerlink" title="查看方式"></a>查看方式</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">https://www.bilibili.com</span><br><span class="line">👇👇👇👇👇👇👇👇👇👇👇👇👇👇</span><br><span class="line">https://www.bilibili.com/robots.txt</span><br></pre></td></tr></table></figure>

<h1 id="requests"><a href="#requests" class="headerlink" title="requests"></a>requests</h1><h2 id="先来一个例子看一下使用过程"><a href="#先来一个例子看一下使用过程" class="headerlink" title="先来一个例子看一下使用过程"></a>先来一个例子看一下使用过程</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.get(<span class="string">&quot;http://www.baidu.com&quot;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.status_code</span><br><span class="line"><span class="number">200</span>   <span class="comment">#状态码，200表明成功</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.encoding = <span class="string">&#x27;utf-8&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.text</span><br><span class="line"><span class="string">&#x27;&lt;!DOCTYPE html&gt;\r\n&lt;!--STATUS OK--&gt;&lt;html&gt; &lt;head&gt;&lt;meta http-equiv=content-type content=text/html;charset=utf-8&gt;&lt;meta http-equiv=X-UA-Compatible content=IE=Edge&gt;&lt;meta content=always name=referrer&gt;&lt;link rel=stylesheet type=text/css href=http://s1.bdstatic.com/r/www/cache/bdorz/baidu.min.css&gt;&lt;title&gt;百度一下，你就知道&lt;/title&gt;&lt;/head&gt; &lt;body link=#0000cc&gt; &lt;div id=wrapper&gt; &lt;div id=head&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>通过get获取web页面源代码和发送请求</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">page_text = requests.get(url,params,headers)</span><br></pre></td></tr></table></figure>

<p>通过post发送请求并获取响应内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">response = requests.post(url,data,headers)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">如果返回json字符串,用.json()</span><br><span class="line">返回普通字符串,用.text()</span><br></pre></td></tr></table></figure>



<p>以下内容已经忘记。。。</p>
<p>主要方法，也就用到get。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">requests.request()  <span class="comment">#构造一个请求，支撑一下各种方法</span></span><br><span class="line"></span><br><span class="line">requests.get()    <span class="comment">#获取HTML网页</span></span><br><span class="line"></span><br><span class="line">requests.head()   <span class="comment">#获取HTML网页头信息</span></span><br><span class="line"></span><br><span class="line">requests.post()   <span class="comment">#不改变原数据添加新数据</span></span><br><span class="line"></span><br><span class="line">requests.put()    <span class="comment">#覆盖原数据添加数据</span></span><br><span class="line"></span><br><span class="line">requests.patch()    <span class="comment">#局部修改请求</span></span><br><span class="line"></span><br><span class="line">requests.delete()   <span class="comment">#删除请求</span></span><br></pre></td></tr></table></figure>



<hr>
<p>可用request()来执行其他方法，也可以直接用其他requests库的方法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requests.request(method,url,**kwargs)</span><br></pre></td></tr></table></figure>

<p>第一个参数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">r = requests.request(&#x27;GET&#x27;,url,**kwargs)</span><br><span class="line"></span><br><span class="line">#参数</span><br><span class="line">&#x27;GET&#x27;  &#x27;HEAD&#x27;  &#x27;POST&#x27;  &#x27;PUT&#x27;  &#x27;PATCH&#x27;  &#x27;PUT&#x27;  &#x27;POST&#x27;  &#x27;delete&#x27;  &#x27;OPTIONS&#x27;</span><br></pre></td></tr></table></figure>

<p>第二个参数就是网址，直接看第三个参数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">r = requests.request(method,url,params=kv)</span><br><span class="line"></span><br><span class="line">#参数(其余主要方法适用)</span><br><span class="line">params:字典或字节序列，作为参数增加到返回的url中</span><br><span class="line">    </span><br><span class="line">data:字典、字节序列或文件对象，提交数据</span><br><span class="line">    </span><br><span class="line">json:JSON格式的数据，提交使用</span><br><span class="line">    </span><br><span class="line">headers:字典，HTTP定制头</span><br><span class="line">    </span><br><span class="line">cookies:字典或CookieJar,Request中的cookie</span><br><span class="line">    </span><br><span class="line">auth:元组</span><br><span class="line">    </span><br><span class="line">files:字典类型，传输文件</span><br><span class="line"></span><br><span class="line">timeout:设定超时时间，秒为单位</span><br><span class="line"></span><br><span class="line">proxies:字典类型，设定访问代理服务器，可以增加登录认证</span><br><span class="line"></span><br><span class="line">allow_redirects:重定向,默认True</span><br><span class="line"></span><br><span class="line">stream:获取内容立即下载，默认True</span><br><span class="line"></span><br><span class="line">verify:认证SSL证书开关，默认True</span><br><span class="line"></span><br><span class="line">cert:本地SSL证书路径</span><br></pre></td></tr></table></figure>



<hr>
<p>get()方法后，处理数据的一些方法，不加括号哟~~</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">r = requests.get(url,params=<span class="literal">None</span>,**kwargs)   </span><br><span class="line"><span class="comment">#get构造向服务器请求资源的Request对象</span></span><br><span class="line"><span class="comment">#requests返回包含服务器资源的Response对象</span></span><br><span class="line"></span><br><span class="line">r.status_code   <span class="comment">#Http请求的返回状态，200表示连接成功，404表示失败</span></span><br><span class="line"></span><br><span class="line">r.text    <span class="comment">#响应内容的字符串形式，url对应的页面内容</span></span><br><span class="line"></span><br><span class="line">r.encoding   <span class="comment">#在HTTP header中猜测的响应内容编码方式</span></span><br><span class="line"></span><br><span class="line">r.apparent_encoding     <span class="comment">#从内容分析出编码方式</span></span><br><span class="line"></span><br><span class="line">r.content    <span class="comment">#响应内容的二进制形式</span></span><br><span class="line"></span><br><span class="line">r.raise_for_ataus()  <span class="comment">#当状态不是200时，引起HTTPError异常</span></span><br><span class="line"></span><br><span class="line">r.header   <span class="comment">#</span></span><br></pre></td></tr></table></figure>



<hr>
<p>post()与put()方法的使用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">r = post(url,data=<span class="literal">None</span>,json=<span class="literal">None</span>,**kwargs)</span><br><span class="line">r = put(url,data=<span class="literal">None</span>,**kwargs)</span><br><span class="line"></span><br><span class="line">payload = &#123;<span class="string">&#x27;key1&#x27;</span>:<span class="string">&#x27;value1&#x27;</span>,<span class="string">&#x27;key2&#x27;</span>:<span class="string">&#x27;value2&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">r = requests.post(<span class="string">&#x27;http://httpbin.org/post&#x27;</span>,data = payload)</span><br><span class="line"></span><br><span class="line">r.text</span><br></pre></td></tr></table></figure>



<h2 id="异常"><a href="#异常" class="headerlink" title="异常"></a>异常</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">requests.ConnectionError <span class="comment">#网络连接错误异常</span></span><br><span class="line"></span><br><span class="line">requests.HTTPError   <span class="comment">#HTTP错误异常</span></span><br><span class="line"></span><br><span class="line">requests.URLRequired  <span class="comment">#URL缺失异常</span></span><br><span class="line"></span><br><span class="line">requests.TooManyRedirects  <span class="comment">#超过最大重定向次数，产生重定向异常</span></span><br><span class="line"></span><br><span class="line">requests.ConnectTimeout  <span class="comment">#连接远程服务器超时异常</span></span><br><span class="line"></span><br><span class="line">requests.Timeout  <span class="comment">#请求URL超时，产生超时异常</span></span><br></pre></td></tr></table></figure>

<h2 id="传参"><a href="#传参" class="headerlink" title="传参"></a>传参</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">param = &#123;&quot;query&quot;:kw&#125;</span><br><span class="line"></span><br><span class="line">requests.get(url,params=param)</span><br></pre></td></tr></table></figure>

<h2 id="代码框架"><a href="#代码框架" class="headerlink" title="代码框架"></a>代码框架</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getHTMLText</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> r.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;产生异常&quot;</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(fileName,<span class="string">&quot;w&quot;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">    fp.write(getHTML(url))</span><br></pre></td></tr></table></figure>

<h1 id="数据分析"><a href="#数据分析" class="headerlink" title="数据分析"></a>数据分析</h1><h2 id="re"><a href="#re" class="headerlink" title="re"></a>re</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">text_html = requests.get(url,headers = header).text</span><br><span class="line">r1 = re.findall(<span class="string">&#x27;&lt;img src=&quot;(.*?)&quot;&#x27;</span>,text1,re.S)</span><br></pre></td></tr></table></figure>

<h2 id="bs4"><a href="#bs4" class="headerlink" title="bs4"></a>bs4</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">soup.title</span><br><span class="line"></span><br><span class="line">find()</span><br><span class="line"></span><br><span class="line">find_all()</span><br><span class="line"></span><br><span class="line">select()</span><br></pre></td></tr></table></figure>

<h2 id="xpath"><a href="#xpath" class="headerlink" title="xpath"></a>xpath</h2><p>实例化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="comment"># 本地html文件</span></span><br><span class="line">e = etree.parse(filePath)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 网络html</span></span><br><span class="line">e = etree.HTML(<span class="string">&#x27;page_text&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>e.xpath()分析</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查找标签</span></span><br><span class="line">r = etree1.xpath(<span class="string">&#x27;/html/body/div&#x27;</span>)</span><br><span class="line">r = etree1.xpath(<span class="string">&#x27;/html//div&#x27;</span>)</span><br><span class="line">r = etree1.xpath(<span class="string">&#x27;//div&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#查找id或class属性标签</span></span><br><span class="line">r = etree1.xpath(<span class="string">&#x27;//div[@id=&quot;top_left_menu&quot;]&#x27;</span>)   <span class="comment"># id可更改</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#根据索引查找标签</span></span><br><span class="line">r = etree1.xpath(<span class="string">&#x27;/html/body/div[2]&#x27;</span>)   <span class="comment">#从1开始</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#查看标签文本</span></span><br><span class="line">r = etree1.xpath(<span class="string">&#x27;//div[@id=&quot;top_right_nav&quot;]//li[3]/a/text()&#x27;</span>)</span><br><span class="line">r = etree1.xpath(<span class="string">&#x27;//div[@id=&quot;top_right_nav&quot;]//li[3]//text()&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看属性内容</span></span><br><span class="line">r = etree1.xpath(<span class="string">&#x27;//div[@id=&quot;top_right_nav&quot;]//li[3]/a/@href&#x27;</span>)   <span class="comment"># href可更改</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#查询多个</span></span><br><span class="line">r = etree1.xpath(<span class="string">&#x27;/html/body/div[2] | /html//li&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="UA伪装"><a href="#UA伪装" class="headerlink" title="UA伪装"></a>UA伪装</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.get(<span class="string">&quot;https://www.amazon.cn/&quot;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.status_code</span><br><span class="line"><span class="number">503</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.encoding=<span class="string">&#x27;utf-8&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r.text</span><br><span class="line">抱歉，我们只是想确认一下当前访问者并非自动程序。为了达到最佳效果，请确保您浏览器上的 Cookie 已启用。</span><br></pre></td></tr></table></figure>

<p>不让用爬虫爬取，就只能UA伪装了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; kv = &#123;<span class="string">&#x27;user-agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0&#x27;</span>&#125;</span><br><span class="line">&gt;&gt; r = requests.get(<span class="string">&quot;http://www.baidu.com&quot;</span>,headers = kv)</span><br><span class="line">&gt;&gt; r.status_code</span><br><span class="line"><span class="number">200</span></span><br></pre></td></tr></table></figure>

<p>这样就可以让网站认为我们不是爬虫强盗，而是一个浏览器良民</p>
<h1 id="cookie"><a href="#cookie" class="headerlink" title="cookie"></a>cookie</h1><p>cookie能记录登录账户的状态，在不传入cookie值的时候，一般用户处于无状态，访问页面上会回到登录界面，此时就要获取cookie。</p>
<p>cookie可以手动获取,也可以自动获取。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自动获取</span></span><br><span class="line"><span class="comment"># 1、创建session会议对象</span></span><br><span class="line">session = requests.Session()</span><br><span class="line"><span class="comment"># 2、获取cookie</span></span><br><span class="line">cookie = session.post(url1,headers = header,data = data)</span><br><span class="line"><span class="comment"># 3、发送请求时使用</span></span><br><span class="line">html1 = session.get(url2,headers = header)</span><br></pre></td></tr></table></figure>

<p>通过cookie爬取个人主页信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="comment"># 头和数据</span></span><br><span class="line">url1 = <span class="string">&#x27;http://www.renren.com/ajaxLogin/login?1=1&amp;uniqueTimestamp=2021241645482&#x27;</span>   <span class="comment"># 不是登录网址,是post请求网址</span></span><br><span class="line">header = &#123;<span class="string">&#x27;user-agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.190 Safari/537.36&#x27;</span>&#125;</span><br><span class="line">data = &#123;<span class="string">&#x27;email&#x27;</span>: <span class="number">18462112993</span>,</span><br><span class="line">        <span class="string">&#x27;icode&#x27;</span>: <span class="string">&#x27;&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;origURL&#x27;</span>: <span class="string">&#x27;http://www.renren.com/home&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;domain&#x27;</span>: <span class="string">&#x27;renren.com&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;key_id&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="string">&#x27;captcha_type&#x27;</span>: <span class="string">&#x27;web_login&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;password&#x27;</span>: <span class="string">&#x27;3b59a34d3bc0f41c5586bd3e3b877f96d35c36b80aa591a7c16d77aac183c288&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;rkey&#x27;</span>: <span class="string">&#x27;b1634001494bab736ead64191d98a368&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;f&#x27;</span>: <span class="string">&#x27;http%3A%2F%2Fwww.renren.com%2F976410969&#x27;</span>&#125;</span><br><span class="line"><span class="comment"># 获取cookie值</span></span><br><span class="line">session = requests.Session()   <span class="comment"># 创建session会议对象</span></span><br><span class="line">cookie = session.post(url1,headers = header,data = data)   <span class="comment"># 使用session返回cookie值</span></span><br><span class="line"><span class="built_in">print</span>(cookie.status_code)</span><br><span class="line"><span class="comment"># 爬取主页</span></span><br><span class="line">url2 = <span class="string">&#x27;http://www.renren.com/976410969/profile&#x27;</span></span><br><span class="line">html1 = session.get(url2,headers = header)   <span class="comment"># 将session替换requests直接包含cookie信息</span></span><br><span class="line">html2 = html1.content   <span class="comment"># 转二进制</span></span><br><span class="line"><span class="comment">#存储</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./web.html&#x27;</span>,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(html2)</span><br><span class="line">    f.close()</span><br></pre></td></tr></table></figure>

<h1 id="代理"><a href="#代理" class="headerlink" title="代理"></a>代理</h1><p>通过更改ip防止被封ip的反爬机制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 爬取的网站如果是https则使用https协议的代理服务器,http网站则对应http协议的代理服务器</span></span><br><span class="line">html1 = requests.get(url1,headers = header,proxies=&#123;<span class="string">&#x27;http&#x27;</span>:<span class="string">&#x27;120.83.101.39:9999&#x27;</span>&#125;).text</span><br></pre></td></tr></table></figure>

<p>免费的代理服务器都连不上哎，不过用梯子到也可以改变ip。</p>
<h1 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h1><h2 id="greenlet模块"><a href="#greenlet模块" class="headerlink" title="greenlet模块"></a>greenlet模块</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> greenlet <span class="keyword">import</span> greenlet</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func1</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">1</span>)</span><br><span class="line">    gr2.switch()</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">2</span>)</span><br><span class="line">    gr2.switch()</span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func2</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">3</span>)</span><br><span class="line">    gr1.switch()</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">4</span>)</span><br><span class="line">    </span><br><span class="line">gr1 = greenlet(func1)</span><br><span class="line">gr2 = greenlet(func2)</span><br><span class="line"></span><br><span class="line">gr1.switch()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1 3 2 4</span></span><br></pre></td></tr></table></figure>

<h2 id="yield关键字"><a href="#yield关键字" class="headerlink" title="yield关键字"></a>yield关键字</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">func1</span>():</span><br><span class="line">    <span class="keyword">yield</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">yield</span> <span class="keyword">from</span> func2()</span><br><span class="line">    <span class="keyword">yield</span> <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func2</span>():</span><br><span class="line">    <span class="keyword">yield</span> <span class="number">3</span></span><br><span class="line">    <span class="keyword">yield</span> <span class="number">4</span></span><br><span class="line"></span><br><span class="line">f1 = func1()</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> f1:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;123&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(item)</span><br></pre></td></tr></table></figure>

<h2 id="asyncio装饰器-3-4"><a href="#asyncio装饰器-3-4" class="headerlink" title="asyncio装饰器(3.4)"></a>asyncio装饰器(3.4)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line"><span class="meta">@asyncio.coroutine</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func1</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">yield</span> <span class="keyword">from</span> asyncio.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@asyncio.coroutine</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func2</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">yield</span> <span class="keyword">from</span> asyncio.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">tasks = [</span><br><span class="line">    asyncio.ensure_future(func1()),</span><br><span class="line">    asyncio.ensure_future(func2())</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(asyncio.wait(tasks))</span><br></pre></td></tr></table></figure>

<h2 id="asyn、await关键字-3-5"><a href="#asyn、await关键字-3-5" class="headerlink" title="asyn、await关键字(3.5)"></a>asyn、await关键字(3.5)</h2><p>await后跟：协程对象、task对象、Future、IO等待</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">func1</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">await</span> asyncio.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">func2</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">await</span> asyncio.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">tasks = [</span><br><span class="line">    asyncio.ensure_future(func1()),</span><br><span class="line">    asyncio.ensure_future(func2())</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(asyncio.wait(tasks))</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">func</span>():   <span class="comment"># 协程函数</span></span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&#x27;Hellow World&#x27;</span>)</span><br><span class="line"></span><br><span class="line">result = func()   <span class="comment"># 协程对象</span></span><br><span class="line"></span><br><span class="line">asyncio.run(result)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Hellow World</span></span><br></pre></td></tr></table></figure>

<h2 id="Task对象"><a href="#Task对象" class="headerlink" title="Task对象"></a>Task对象</h2><p>创建方法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">asyncio.create_task()</span><br><span class="line"></span><br><span class="line">loop.create_task()</span><br><span class="line"></span><br><span class="line">asyncio.ensure_future()   # 3.7创建future对象</span><br></pre></td></tr></table></figure>

<p>task的使用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">func</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">await</span> asyncio.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;fanhui&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;main play&#x27;</span>)</span><br><span class="line">    task_list = [</span><br><span class="line">    <span class="comment">#asyncio.create_task(func(),name=&#x27;n1&#x27;) 可以给定名称</span></span><br><span class="line">    asyncio.create_task(func()),</span><br><span class="line">    asyncio.create_task(func())</span><br><span class="line">    ]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;main end&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># done:返回值集合,pending未完成任务集合。</span></span><br><span class="line">    <span class="comment">#done,pending = await asyncio.wait(task_list,timeout=None) 可以给定等待时间</span></span><br><span class="line">    done,pending = <span class="keyword">await</span> asyncio.wait(task_list)</span><br><span class="line">    <span class="built_in">print</span>(done,pending)</span><br><span class="line"></span><br><span class="line">asyncio.run(main())</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">func</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">await</span> asyncio.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;fanhui&#x27;</span></span><br><span class="line"></span><br><span class="line">task_list = [</span><br><span class="line">    func(),</span><br><span class="line">    func()</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">asyncio.run(asyncio.wait(task_list))</span><br></pre></td></tr></table></figure>



<h1 id="异步爬虫"><a href="#异步爬虫" class="headerlink" title="异步爬虫"></a>异步爬虫</h1><p>进程池或协程实现</p>
<h1 id="aiohttp"><a href="#aiohttp" class="headerlink" title="aiohttp"></a>aiohttp</h1><p>基于异步网络请求的模块</p>
<p>通过协程实现梨视频项目爬取</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing,os</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line">u = []</span><br><span class="line">vs = []</span><br><span class="line">url1 = <span class="string">&#x27;https://www.pearvideo.com/category_5&#x27;</span></span><br><span class="line">header1 = &#123;</span><br><span class="line">   <span class="string">&#x27;user-agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.190 Safari/537.36&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 获取具体页面</span></span><br><span class="line">html1 = requests.get(url1,headers = header1).text</span><br><span class="line">e1 = etree.HTML(html1)</span><br><span class="line">list1 = e1.xpath(<span class="string">&#x27;//div[@class=&quot;category-top&quot;]//div[@class=&quot;vervideo-bd&quot;]/a/@href&#x27;</span>)</span><br><span class="line"><span class="comment"># 具体页面获取视频</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">worker</span>(<span class="params">url2</span>):</span><br><span class="line">    header2 = &#123;</span><br><span class="line">        <span class="string">&#x27;Referer&#x27;</span>: url2,</span><br><span class="line">        <span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.190 Safari/537.36&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># 获取contid</span></span><br><span class="line">    contid = url2[-<span class="number">7</span>:]</span><br><span class="line">    url3 = <span class="string">&#x27;https://www.pearvideo.com/videoStatus.jsp?contId=&#123;&#125;&amp;mrd=0.9425787259180061&#x27;</span>.<span class="built_in">format</span>(contid)</span><br><span class="line">    u1 = requests.post(url3, headers=header2).text</span><br><span class="line">    u2 = re.findall(<span class="string">&#x27;&quot;srcUrl&quot;:&quot;(.*?)&quot;&#x27;</span>, u1)[<span class="number">0</span>]</span><br><span class="line">    u3 = u2.replace(re.findall(<span class="string">&#x27;adshort/.*/(.*?)-&#x27;</span>, u2)[<span class="number">0</span>], <span class="string">&#x27;cont-&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(contid))</span><br><span class="line">    <span class="keyword">return</span> u3</span><br><span class="line">------------------------------------------------------------------------------------------------------------</span><br><span class="line">主要部分主要部分主要部分主要部分主要部分主要部分主要部分主要部分主要部分主要部分主要部分主要部分主要部分主要部分主要部分主要部分</span><br><span class="line"><span class="comment"># aiohttp请求</span></span><br><span class="line"><span class="keyword">async</span>  <span class="keyword">def</span> <span class="title function_">video</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;开始下载&#x27;</span>)</span><br><span class="line">        <span class="comment"># 使用代理ip时，proxy = &#x27;http://ip:端口&#x27;</span></span><br><span class="line">        <span class="keyword">async</span> <span class="keyword">with</span> <span class="keyword">await</span> session.get(url) <span class="keyword">as</span> response:</span><br><span class="line">            page_text =<span class="keyword">await</span> response.content.read()   <span class="comment"># 为什么要用read()</span></span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./&#123;&#125;.mp4&#x27;</span>.<span class="built_in">format</span>(url[-<span class="number">20</span>:-<span class="number">16</span>]),<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write(page_text)</span><br><span class="line">                f.close()</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;下载完成&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> list1:</span><br><span class="line">    i = <span class="string">&#x27;https://www.pearvideo.com/&#x27;</span> + i</span><br><span class="line">    urls = worker(i)</span><br><span class="line">    u.append(urls)</span><br><span class="line"></span><br><span class="line">tasks = [video(u[<span class="number">0</span>])，video(u[<span class="number">1</span>])，video(u[<span class="number">2</span>])，video(u[<span class="number">3</span>])]</span><br><span class="line">asyncio.run(asyncio.wait(tasks))</span><br></pre></td></tr></table></figure>

<h1 id="selenium"><a href="#selenium" class="headerlink" title="selenium"></a>selenium</h1><p>谷歌浏览器驱动下载地址：</p>
<p><a target="_blank" rel="noopener" href="http://chromedriver.storage.googleapis.com/index.html">http://chromedriver.storage.googleapis.com/index.html</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://www.taobao.com/&#x27;</span></span><br><span class="line">bro = webdriver.Chrome(executable_path=<span class="string">&#x27;./chromedriver&#x27;</span>)</span><br><span class="line">bro.get(url)</span><br><span class="line">html = bro.page_source   <span class="comment"># 连同动态数据一同获得</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#获取标签内容</span></span><br><span class="line">title1 = bro.find_element_by_id(<span class="string">&#x27;q&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(title1.text)</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取标签属性</span></span><br><span class="line">link = goods.find_element_by_tag_name(<span class="string">&#x27;a&#x27;</span>).get_attribute(<span class="string">&#x27;href&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#标签互动</span></span><br><span class="line">title1 = bro.find_element_by_id(<span class="string">&#x27;q&#x27;</span>)</span><br><span class="line">title1.send_keys(<span class="string">&#x27;我的世界&#x27;</span>)</span><br><span class="line">sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#执行js</span></span><br><span class="line">bro.execute_script(<span class="string">&#x27;window.scrollTo(0,document.body.scrollHeight)&#x27;</span>)</span><br><span class="line">sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#按钮互动</span></span><br><span class="line">button1 = bro.find_element_by_css_selector(<span class="string">&#x27;.tb-bg&#x27;</span>)</span><br><span class="line">button1.click()</span><br><span class="line">sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#回退</span></span><br><span class="line">bro.back()</span><br><span class="line">sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#关闭浏览器</span></span><br><span class="line">bro.quit()</span><br></pre></td></tr></table></figure>

<p>处理iframe</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 动作链模组引入</span></span><br><span class="line"><span class="keyword">from</span> selenium.webdriver <span class="keyword">import</span> ActionChains</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切换浏览器标签定位的作用域</span></span><br><span class="line">bro.switch_to.frame(&lt;<span class="built_in">id</span>&gt;)</span><br><span class="line">div = bro.find_.....</span><br><span class="line"></span><br><span class="line"><span class="comment"># 动作链</span></span><br><span class="line">action = ActionChains(bro)   <span class="comment"># 定义动作链对象</span></span><br><span class="line"><span class="comment"># 点击长按</span></span><br><span class="line">action.click_and_hold(div)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    <span class="comment"># 移动标签(x,y)</span></span><br><span class="line">    <span class="comment">#perform()立即执行</span></span><br><span class="line">    action.move_by_offset(<span class="number">17</span>,<span class="number">0.</span>perform()</span><br><span class="line">    sleep(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 释放动作链</span></span><br><span class="line">action.release()</span><br></pre></td></tr></table></figure>

<p>无可视化界面</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium.webdriver.chrome.options <span class="keyword">import</span> Options</span><br><span class="line"></span><br><span class="line">options = Options()</span><br><span class="line">options.add_argument(<span class="string">&#x27;--headless&#x27;</span>)</span><br><span class="line">options.add_argument(<span class="string">&#x27;--disable-gpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">bro = webdriver.Chrome(executable_path=<span class="string">&#x27;./chromedriver&#x27;</span>,options=options)</span><br></pre></td></tr></table></figure>

<p>规避检查</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">bro.execute_cdp_cmd(<span class="string">&quot;Page.addScriptToEvaluateOnNewDocument&quot;</span>, &#123;</span><br><span class="line">  <span class="string">&quot;source&quot;</span>: <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Object.defineProperty(navigator, &#x27;webdriver&#x27;, &#123;</span></span><br><span class="line"><span class="string">      get: () =&gt; undefined</span></span><br><span class="line"><span class="string">    &#125;)</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>

<h1 id="scrapy框架"><a href="#scrapy框架" class="headerlink" title="scrapy框架"></a>scrapy框架</h1><p>1.创建工程</p>
<p>scrapy startproject projectname</p>
<p>2.在spiders中创建爬虫</p>
<p>scrapy genspider test <a target="_blank" rel="noopener" href="http://www.xxx.com/">www.xxx.com</a></p>
<p>3.运行爬虫</p>
<p>scrapy crawl test</p>
<p>scrapy crawl test –nolog   不加载文档信息，只显示结果</p>
<h2 id="爬虫编写"><a href="#爬虫编写" class="headerlink" title="爬虫编写"></a>爬虫编写</h2><p><strong>配置</strong></p>
<p>将settings文件内的ROBOTSTXT_OBEY改为False</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ROBOTSTXT_OBEY = <span class="literal">False</span></span><br></pre></td></tr></table></figure>

<p><strong>使用</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&#x27;test&#x27;</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;https://www.qiushibaike.com/text/&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">        user = response.xpath(<span class="string">&#x27;.//div[@class=&quot;article block untagged mb15 typs_hot&quot;]&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> user:</span><br><span class="line">            user1 = i.xpath(<span class="string">&#x27;./div/a[2]/h2/text()&#x27;</span>)</span><br><span class="line">            <span class="built_in">print</span>(user1.extract_first())   <span class="comment"># _frist()输出列表第一个内容</span></span><br><span class="line">            text1 = i.xpath(<span class="string">&#x27;.//div[@class=&quot;content&quot;]/span[1]/text()&#x27;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>.join(text1.extract() ) )   <span class="comment"># extracr()输出data内容</span></span><br></pre></td></tr></table></figure>

<h2 id="持久化存储"><a href="#持久化存储" class="headerlink" title="持久化存储"></a>持久化存储</h2><p>5.1基于终端指令</p>
<p>scrapy crawl test -o .&#x2F;text.csv</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 只能将parse方法的返回值存储</span></span><br><span class="line">	<span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">        list1 = []</span><br><span class="line">        user = response.xpath(<span class="string">&#x27;.//div[@class=&quot;article block untagged mb15 typs_hot&quot;]&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> user:</span><br><span class="line">            user1 = i.xpath(<span class="string">&#x27;./div/a[2]/h2/text()&#x27;</span>)</span><br><span class="line">            text1 = i.xpath(<span class="string">&#x27;.//div[@class=&quot;content&quot;]/span[1]/text()&#x27;</span>)</span><br><span class="line">            dic = &#123;<span class="string">&#x27;user&#x27;</span>:user1，</span><br><span class="line">                   <span class="string">&#x27;text&#x27;</span>:text1&#125;</span><br><span class="line">            list1.append(dic)</span><br><span class="line">         <span class="keyword">return</span> list1</span><br></pre></td></tr></table></figure>

<p>5.2基于管道</p>
<p>在setttings里开启ITEM_PIPELINES</p>
<p>在item里创建对象</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FirstItem</span>(scrapy.Item):</span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    <span class="comment"># name = scrapy.Field()</span></span><br><span class="line">    user1 = scrapy.Field()</span><br><span class="line">    text1 = scrapy.Field()</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<p>在爬虫里创建item对象并将内容传给item,然后将item提交给管道</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> first.items <span class="keyword">import</span> FirstItem</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">    <span class="built_in">sum</span> = <span class="number">0</span></span><br><span class="line">    user = response.xpath(<span class="string">&#x27;.//div[@class=&quot;article block untagged mb15 typs_hot&quot;]&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> user:</span><br><span class="line">        user1 = i.xpath(<span class="string">&#x27;./div/a[2]/h2/text() | ./div/span/h2/text()&#x27;</span>)[<span class="number">0</span>].extract()</span><br><span class="line">        text1 = i.xpath(<span class="string">&#x27;.//div[@class=&quot;content&quot;]/span[1]/text()&#x27;</span>).extract()</span><br><span class="line">        text1 = <span class="string">&#x27;&#x27;</span>.join(text1)</span><br><span class="line">        </span><br><span class="line">        item = FirstItem()</span><br><span class="line">        item[<span class="string">&#x27;user1&#x27;</span>] = user1</span><br><span class="line">        item[<span class="string">&#x27;text1&#x27;</span>] = text1</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> item    <span class="comment"># 将item提交给管道</span></span><br></pre></td></tr></table></figure>

<h2 id="文字存储"><a href="#文字存储" class="headerlink" title="文字存储"></a>文字存储</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FirstPipeline</span>:</span><br><span class="line">    fp = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">open_spider</span>(<span class="params">self,spider</span>):   <span class="comment"># 爬虫开始执行</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;开始爬虫&#x27;</span>)</span><br><span class="line">        self.fp = <span class="built_in">open</span>(<span class="string">&#x27;./text.txt&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">process_item</span>(<span class="params">self, item, spider</span>):   <span class="comment"># 每一个item就执行一次</span></span><br><span class="line">        user1 = item[<span class="string">&#x27;user1&#x27;</span>]   <span class="comment"># 获取item里的内容</span></span><br><span class="line">        text1 = item[<span class="string">&#x27;text1&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        self.fp.write(user1+<span class="string">&#x27;:&#x27;</span>+text1)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> item   <span class="comment"># 将item传给下一个管道</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">close_spider</span>(<span class="params">self,spider</span>):   <span class="comment"># 结束时执行</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;爬虫结束&#x27;</span>)</span><br><span class="line">        self.fp.close()</span><br></pre></td></tr></table></figure>

<h2 id="分页爬取"><a href="#分页爬取" class="headerlink" title="分页爬取"></a>分页爬取</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">    html1 = response.xpath(<span class="string">&#x27;//div[@class=&quot;index_img list_center&quot;]/ul/li&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> html1:</span><br><span class="line">        name1 = i.xpath(<span class="string">&#x27;./a/img/@alt&#x27;</span>).extract_first()</span><br><span class="line">        <span class="built_in">print</span>(name1)</span><br><span class="line">    <span class="keyword">if</span> self.page_num &lt;= <span class="number">5</span>:</span><br><span class="line">        new_url = <span class="built_in">format</span>(self.url%self.page_num)</span><br><span class="line">        self.page_num += <span class="number">1</span></span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(url=new_url,callback=self.parse)   <span class="comment"># 手动请求并回调方法</span></span><br></pre></td></tr></table></figure>

<h2 id="深度爬取"><a href="#深度爬取" class="headerlink" title="深度爬取"></a>深度爬取</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">parse_detail</span>(<span class="params">self,response</span>):</span><br><span class="line">    item = response.meta[<span class="string">&#x27;item&#x27;</span>]</span><br><span class="line">    job_desc = response.xpath(<span class="string">&#x27;xxx&#x27;</span>)</span><br><span class="line">    job_desc = <span class="string">&#x27;&#x27;</span>.jpin(job_desc)</span><br><span class="line">	item[<span class="string">&#x27;job_desc&#x27;</span>] = job_desc</span><br><span class="line">    <span class="keyword">yield</span> item</span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self,response</span>)</span><br><span class="line">	li_list = response.xpath(<span class="string">&#x27;xxx&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">        item = firstItem()</span><br><span class="line">        </span><br><span class="line">        job_name = li.xpath(<span class="string">&#x27;xxx&#x27;</span>).extract()</span><br><span class="line">        item[<span class="string">&#x27;job_name&#x27;</span>] = job_name</span><br><span class="line">        detail_url = <span class="string">&#x27;第二层网址&#x27;</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(detail_url,callback=self.parse_detail,meta=&#123;<span class="string">&#x27;item&#x27;</span>:item&#125;)</span><br></pre></td></tr></table></figure>

<h2 id="图片存储"><a href="#图片存储" class="headerlink" title="图片存储"></a>图片存储</h2><p>8.1在item里创建src图片链接对象</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FirstItem</span>(scrapy.Item):</span><br><span class="line">    src = scrapy.Field()</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<p>8.2在爬虫里获取图片链接，创建item对象，将链接传给item[‘src’]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> first.items <span class="keyword">import</span> FirstItem</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TestSpider</span>(scrapy.Spider):</span><br><span class="line">    name = <span class="string">&#x27;test&#x27;</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;https://sc.chinaz.com/tupian/&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse</span>(<span class="params">self, response</span>):</span><br><span class="line">        html1 = response.xpath(<span class="string">&#x27;//div[@id=&quot;container&quot;]/div&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> html2 <span class="keyword">in</span> html1:</span><br><span class="line">            src = <span class="string">&#x27;https:&#x27;</span>+html2.xpath(<span class="string">&#x27;./div/a/img/@src2&#x27;</span>).extract_first()</span><br><span class="line">            item = FirstItem()</span><br><span class="line">            item[<span class="string">&#x27;src&#x27;</span>] = src</span><br><span class="line">            <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure>

<p>8.3在管道里创建图片存储的类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.pipelines.images <span class="keyword">import</span> ImagesPipeline</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">imgsPileLine</span>(<span class="title class_ inherited__">ImagesPipeline</span>):</span><br><span class="line">    <span class="comment"># 图片数据请求</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_media_requests</span>(<span class="params">self, item, info</span>):</span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(item[<span class="string">&#x27;src&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 指定图片存储路径，request为请求后的对象</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">file_path</span>(<span class="params">self, request, response=<span class="literal">None</span>, info=<span class="literal">None</span>, *, item=<span class="literal">None</span></span>):</span><br><span class="line">        imgName = request.url.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>]   <span class="comment"># 指定名称</span></span><br><span class="line">        <span class="keyword">return</span> imgName</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将item返回给下一个被执行的管道类</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">item_completed</span>(<span class="params">self, results, item, info</span>):</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>

<p>8.4在setting里添加图片存储路径，并且更改管道名称</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 指定图片存储的目录</span></span><br><span class="line">IMAGES_STORE = <span class="string">&#x27;./imgs&#x27;</span></span><br><span class="line"></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="string">&#x27;first.pipelines.imgsPileLine&#x27;</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="CrawlSpider"><a href="#CrawlSpider" class="headerlink" title="CrawlSpider"></a>CrawlSpider</h2><p>创建爬虫</p>
<p>scrapy genspider -t crawl name <a target="_blank" rel="noopener" href="http://www.xxx.com/">www.xxx.com</a></p>
<p>编写爬虫</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">QuanSpider</span>(<span class="title class_ inherited__">CrawlSpider</span>):</span><br><span class="line">    name = <span class="string">&#x27;quan&#x27;</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;http://wz.sun0769.com/political/index/supervise?page=1&#x27;</span>]</span><br><span class="line">	</span><br><span class="line">    <span class="comment"># 链接提取器</span></span><br><span class="line">    link = LinkExtractor(allow=<span class="string">r&#x27;page=\d+&#x27;</span>)</span><br><span class="line">    link_detail = LinkExtractor(allow=<span class="string">r&#x27;xxx&#x27;</span>)</span><br><span class="line">    <span class="comment"># 填入链接的正则</span></span><br><span class="line">    rules = (</span><br><span class="line">        <span class="comment"># 规则解析器</span></span><br><span class="line">        Rule(link, callback=<span class="string">&#x27;parse_item&#x27;</span>, follow=<span class="literal">True</span>),   <span class="comment"># False爬取当前页面，True爬取全站链接</span></span><br><span class="line">    	Rule(link, callback=<span class="string">&#x27;parse_detail&#x27;</span>)   <span class="comment"># parse_detail自己编写</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure>

<h1 id="伪链接、伪属性"><a href="#伪链接、伪属性" class="headerlink" title="伪链接、伪属性"></a>伪链接、伪属性</h1><p>伪链接：由真链接和一些其他字符组成，自己根据真链接慢慢改吧</p>
<p>伪属性：一些网站的属性是动态加载的，在爬取的时候用的的反而是伪属性，真属性爬取只能爬取到动态加载出来的，而爬虫无界面。</p>
<h1 id="分布式爬虫"><a href="#分布式爬虫" class="headerlink" title="分布式爬虫"></a>分布式爬虫</h1><p>基于crawlspider通过scrapy-redis组件，指定相同的管道和调度器，通过redis数据库进行存储。</p>
<p>搭建方式，想搞再百度吧。。</p>
<h1 id="爬取搜索结果"><a href="#爬取搜索结果" class="headerlink" title="爬取搜索结果"></a>爬取搜索结果</h1><p>先附上关键词接口</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">百度：http://www.baidu.com/s?wd=keyword</span><br><span class="line">360：http://www.so.com/s?q=keyword</span><br></pre></td></tr></table></figure>

<p>接下来是代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> requests</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>kv = &#123;<span class="string">&#x27;wd&#x27;</span>:<span class="string">&#x27;Python&#x27;</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>r = requests.get(<span class="string">&quot;http://www.baidu.com/s&quot;</span>,params = kv)</span><br></pre></td></tr></table></figure>

<h1 id="图片爬取"><a href="#图片爬取" class="headerlink" title="图片爬取"></a>图片爬取</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url = <span class="string">&quot;http://img0.dili360.com/pic/2020/07/13/5f0bc0add82ed2q84362951.jpg&quot;</span></span><br><span class="line">path = <span class="string">&quot;D://test.jpg&quot;</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    r = requests.get(url)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(path,<span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(r.content)   <span class="comment">#将r转换为二进制形式</span></span><br><span class="line">        f.close()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;文件保存成功&quot;</span>)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;爬取失败&quot;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="例-淘宝爬取"><a href="#例-淘宝爬取" class="headerlink" title="例 淘宝爬取"></a>例 淘宝爬取</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getHTMLText</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url, timeout=<span class="number">30</span>)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = r.apparent_encoding</span><br><span class="line">        <span class="keyword">return</span> r.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;&quot;</span></span><br><span class="line">     </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parsePage</span>(<span class="params">ilt, html</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        plt = re.findall(<span class="string">r&#x27;\&quot;view_price\&quot;\:\&quot;[\d\.]*\&quot;&#x27;</span>,html)</span><br><span class="line">        tlt = re.findall(<span class="string">r&#x27;\&quot;raw_title\&quot;\:\&quot;.*?\&quot;&#x27;</span>,html)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(plt)):</span><br><span class="line">            price = <span class="built_in">eval</span>(plt[i].split(<span class="string">&#x27;:&#x27;</span>)[<span class="number">1</span>])</span><br><span class="line">            title = <span class="built_in">eval</span>(tlt[i].split(<span class="string">&#x27;:&#x27;</span>)[<span class="number">1</span>])</span><br><span class="line">            ilt.append([price , title])</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;&quot;</span>)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">printGoodsList</span>(<span class="params">ilt</span>):</span><br><span class="line">    tplt = <span class="string">&quot;&#123;:4&#125;\t&#123;:8&#125;\t&#123;:16&#125;&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(tplt.<span class="built_in">format</span>(<span class="string">&quot;序号&quot;</span>, <span class="string">&quot;价格&quot;</span>, <span class="string">&quot;商品名称&quot;</span>))</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> g <span class="keyword">in</span> ilt:</span><br><span class="line">        count = count + <span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(tplt.<span class="built_in">format</span>(count, g[<span class="number">0</span>], g[<span class="number">1</span>]))</span><br><span class="line">         </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    goods = <span class="string">&#x27;书包&#x27;</span></span><br><span class="line">    u=<span class="string">&#x27;https://s.taobao.com/search?q=&#x27;</span></span><br><span class="line">    depth = <span class="number">3</span></span><br><span class="line">    start_url = <span class="string">&#x27;https://s.taobao.com/search?q=&#x27;</span> + goods</span><br><span class="line">    infoList = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(depth):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment">#url = start_url + &#x27;&amp;s=&#x27; + str(44*i)</span></span><br><span class="line">            html = getHTMLText(u)</span><br><span class="line">            <span class="built_in">print</span>(html)</span><br><span class="line">            parsePage(infoList, html)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">    printGoodsList(infoList)</span><br><span class="line">     </span><br><span class="line">main()</span><br></pre></td></tr></table></figure>

</div></section><div id="reward-container"><span class="hty-icon-button button-glow" id="reward-button" title="打赏" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === &quot;none&quot;) ? &quot;block&quot; : &quot;none&quot;;"><span class="icon iconify" data-icon="ri:hand-coin-line"></span></span><div id="reward-comment">I'm so cute. Please give me money.</div></div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>Scary Pig</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="https://scarypig.github.io/myblog/2022/04/27/Python%E7%88%AC%E8%99%AB/" title="Python爬虫">https://scarypig.github.io/myblog/2022/04/27/Python%E7%88%AC%E8%99%AB/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均默认采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 "><span class="icon iconify" data-icon="ri:creative-commons-line"></span><span class="icon iconify" data-icon="ri:creative-commons-by-line"></span><span class="icon iconify" data-icon="ri:creative-commons-nc-line"></span><span class="icon iconify" data-icon="ri:creative-commons-sa-line"></span></a> 许可协议。</li></ul></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/myblog/2022/04/27/python%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/" rel="prev" title="Python网络编程"><span class="icon iconify" data-icon="ri:arrow-left-s-line"></span><span class="post-nav-text">Python网络编程</span></a></div><div class="post-nav-item"><a class="post-nav-next" href="/myblog/2022/04/27/python/" rel="next" title="Python"><span class="post-nav-text">Python</span><span class="icon iconify" data-icon="ri:arrow-right-s-line"></span></a></div></div></div><div class="hty-card" id="comment"></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2019 – 2023 </span><span class="with-love" id="animate"><span class="icon iconify" data-icon="ri:cloud-line"></span></span><span class="author"> Scary Pig</span></div><div class="powered"><span>由 <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> 驱动 v6.3.0</span><span class="footer-separator">|</span><span>主题 - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v1.10.9</span></div></footer></div><a class="hty-icon-button" id="back-to-top" aria-label="back-to-top" href="#"><span class="icon iconify" data-icon="ri:arrow-up-s-line"></span><svg class="progress-circle-container" viewBox="0 0 100 100"><circle class="progress-circle" id="progressCircle" cx="50" cy="50" r="48" fill="none" stroke="#0078E7" stroke-width="2" stroke-linecap="round"></circle></svg></a></body></html>